<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Sdesaireader - OCR + Gujarati Speech</title>
  <style>
    body { font-family: 'Segoe UI', Arial, sans-serif; background:#f4f6f9; margin:0; padding:20px; color:#333; text-align:center; }
    h1 { font-size:1.8rem; margin-bottom:10px; color:#2c3e50; }
    .container { max-width:900px; margin:0 auto; padding:20px; background:#fff; border-radius:12px; box-shadow:0 4px 12px rgba(0,0,0,.08); }
    .upload-area { border:3px dashed #3498db; border-radius:10px; padding:60px 20px; margin:20px 0; cursor:pointer; transition:.3s; }
    .upload-area:hover { background:#ecf0f1; }
    .upload-area.active { background:#d5f4ff; border-color:#2980b9; }
    .upload-area p { font-size:1.15rem; color:#7f8c8d; }
    .file-name { font-size:1rem; color:#2c3e50; margin-top:10px; word-break:break-all; }
    .controls { margin:20px 0; }
    button { background:#3498db; color:#fff; border:none; padding:12px 24px; margin:0 8px; font-size:1rem; border-radius:6px; cursor:pointer; transition:.2s; }
    button:hover { background:#2980b9; }
    button:disabled { background:#c7c7c7; cursor:not-allowed; }
    .status { margin-top:15px; font-size:.95rem; color:#34495e; }
    .status .err { color:#e74c3c; font-weight:600; }
    .progress-bar { width:100%; height:6px; background:#ecf0f1; border-radius:3px; margin-top:10px; overflow:hidden; }
    .progress { height:100%; background:#2ecc71; width:0%; transition:width .2s; }
    .speech-controls { margin-top:20px; display:flex; justify-content:center; align-items:center; gap:10px; flex-wrap:wrap; }
    .speed-slider { width:130px; }
    .output { text-align:left; margin:20px auto 0; max-width:900px; background:#fafafa; border:1px solid #eee; border-radius:8px; padding:12px 14px; height:180px; overflow:auto; white-space:pre-wrap; }
    small.mono { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; color:#7f8c8d; }
  </style>
</head>
<body>
  <div class="container">
    <h1>‚ú® Sdesaireader - OCR + Gujarati Speech</h1>

    <div id="uploadArea" class="upload-area">
      <p>Drag & drop a PDF or image here<br><small>(Scanned documents supported!)</small></p>
      <input type="file" id="fileInput" accept=".pdf,.jpg,.jpeg,.png" style="display:none;" />
    </div>

    <div class="file-name" id="fileName"></div>

    <div class="controls">
      <button id="processBtn" disabled>üîç Extract Text (OCR)</button>
      <button id="readBtn" disabled>üó£Ô∏è Read Aloud</button>
    </div>

    <div class="status" id="status">Ready to process. <small class="mono">(first run downloads OCR models)</small></div>
    <div class="progress-bar"><div id="progress" class="progress"></div></div>

    <div class="speech-controls">
      <label for="speedSlider">Speed:</label>
      <input type="range" id="speedSlider" min="0.5" max="2" step="0.1" value="1" class="speed-slider" />
    </div>

    <div id="output" class="output" placeholder="Extracted text will appear here‚Ä¶"></div>
  </div>

  <!-- Tesseract.js (OCR) -->
  <script src="https://unpkg.com/tesseract.js@v2.1.5/dist/tesseract.min.js"></script>
  <!-- PDF.js (to render PDFs to images) -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
  <script>
    // Configure PDF.js worker
    if (window['pdfjsLib']) {
      pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js';
    }

    const uploadArea = document.getElementById('uploadArea');
    const fileInput = document.getElementById('fileInput');
    const fileName = document.getElementById('fileName');
    const processBtn = document.getElementById('processBtn');
    const readBtn = document.getElementById('readBtn');
    const status = document.getElementById('status');
    const progress = document.getElementById('progress');
    const speedSlider = document.getElementById('speedSlider');
    const output = document.getElementById('output');

    let extractedText = '';
    let detectedLang = 'eng';

    // Open picker
    uploadArea.addEventListener('click', () => fileInput.click());

    // Drag & drop
    uploadArea.addEventListener('dragover', e => { e.preventDefault(); uploadArea.classList.add('active'); });
    uploadArea.addEventListener('dragleave', () => uploadArea.classList.remove('active'));
    uploadArea.addEventListener('drop', e => {
      e.preventDefault();
      uploadArea.classList.remove('active');
      const file = e.dataTransfer.files[0];
      if (file) setFile(file);
    });

    // File chosen
    fileInput.addEventListener('change', e => {
      const file = e.target.files[0];
      if (file) setFile(file);
    });

    function setFile(file) {
      fileName.textContent = file.name;
      processBtn.disabled = false;
      readBtn.disabled = true;
      extractedText = '';
      output.textContent = '';
      status.textContent = 'File selected. Ready to extract text.';
    }

    // Process
    processBtn.addEventListener('click', async () => {
      const file = fileInput.files[0];
      if (!file) return;

      try {
        status.textContent = 'Preparing OCR...';
        progress.style.width = '10%';

        const ocrImage = await fileToImageURL(file);
        await runOCR(ocrImage);

      } catch (e) {
        const msg = (e && (e.message || e.reason || e.status)) ? (e.message || e.reason || e.status) : JSON.stringify(e);
        status.innerHTML = '‚ùå <span class="err">Error during OCR:</span> ' + msg;
        console.error('OCR error:', e);
      }
    });

    async function fileToImageURL(file) {
      if (file.type === 'application/pdf') {
        if (!window['pdfjsLib']) throw new Error('PDF renderer not loaded.');
        // Render first page of PDF to image
        const buf = await file.arrayBuffer();
        const pdf = await pdfjsLib.getDocument({ data: buf }).promise;
        const page = await pdf.getPage(1);
        const viewport = page.getViewport({ scale: 2.0 });
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');
        canvas.width = viewport.width;
        canvas.height = viewport.height;
        await page.render({ canvasContext: ctx, viewport }).promise;
        return canvas.toDataURL('image/png');
      } else {
        // Image file
        return URL.createObjectURL(file);
      }
    }

    async function runOCR(imageURL) {
      progress.style.width = '20%';
      status.textContent = 'Loading OCR engine and Gujarati model (first run may take 10‚Äì20s)...';

      const worker = await Tesseract.createWorker({
        logger: m => {
          if (m && m.progress != null) {
            progress.style.width = Math.max(25, Math.round(m.progress * 100)) + '%';
          }
        },
        // Path that contains guj.traineddata (and many others)
        langPath: 'https://tessdata.projectnaptha.com/4.0.0'
      });

      await worker.load();                       // Load core
      await worker.loadLanguage('eng+guj');      // Load languages
      await worker.initialize('eng+guj');        // Init

      status.textContent = 'Recognizing text...';
      const { data: { text } } = await worker.recognize(imageURL);
      await worker.terminate();

      processText(text || '');
    }

    function processText(text) {
      extractedText = (text || '').trim();
      output.textContent = extractedText;

      if (!extractedText) {
        status.textContent = '‚ö†Ô∏è No text found. Try a sharper image or higher contrast.';
        readBtn.disabled = true;
        return;
      }

      // Detect Gujarati characters
      const isGujarati = /[\u0A80-\u0AFF]/.test(extractedText);
      detectedLang = isGujarati ? 'gu' : 'en';

      status.textContent = `‚úÖ Text extracted (${extractedText.length} chars). Detected: ${isGujarati ? 'Gujarati' : 'English'}.`;
      readBtn.disabled = false;
    }

    // Read aloud
    readBtn.addEventListener('click', () => {
      if (!extractedText) { status.textContent = '‚ùå No text to read. Run OCR first.'; return; }

      const utter = new SpeechSynthesisUtterance(extractedText);
      const voices = speechSynthesis.getVoices();

      // Prefer Gujarati if detected and available
      const guVoice = voices.find(v => v.lang && v.lang.toLowerCase().startsWith('gu'));
      const enVoice = voices.find(v => v.lang && v.lang.toLowerCase().startsWith('en'));

      if (detectedLang === 'gu' && guVoice) utter.voice = guVoice;
      else if (enVoice) utter.voice = enVoice;

      utter.rate = parseFloat(speedSlider.value);
      utter.onstart = () => status.textContent = 'üîä Reading aloud...';
      utter.onend = () => status.textContent = '‚úÖ Finished reading.';
      speechSynthesis.cancel(); // stop any previous
      speechSynthesis.speak(utter);
    });

    // Voice availability notice
    window.speechSynthesis.onvoiceschanged = () => {
      const v = speechSynthesis.getVoices();
      if (!v || v.length === 0) status.textContent += ' (No speech voices available on this device)';
    };
  </script>
</body>
</html>
